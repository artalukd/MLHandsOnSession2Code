{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>TensorFlow Basics</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf #convention to import tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A tensor consists of a set of primitive values shaped into an array of any number of dimensions.<br> A tensor's rank is its number of dimensions.\n",
    "Bellow are some tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const:0\", shape=(), dtype=float32) Tensor(\"Const_1:0\", shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "node1 = tf.constant(3.0, tf.float32)\n",
    "node2 = tf.constant([4.0,3.22445,8]) # also tf.float32 implicitly\n",
    "print(node1, node2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>You might think of TensorFlow Core programs as consisting of two discrete sections:</b>\n",
    "\n",
    "    Building the computational graph.\n",
    "    Running the computational graph.\n",
    "A computational graph is a series of TensorFlow operations arranged into a graph of nodes. Let's build a simple computational graph. Each node takes zero or more tensors as inputs and produces a tensor as an output. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To actually evaluate the nodes, we must run the computational graph within a session. A session encapsulates the control and state of the TensorFlow runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.0, array([ 4.        ,  3.22445011,  8.        ], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "print(sess.run([node1, node2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Adding two tensors</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node3:  Tensor(\"Add:0\", shape=(3,), dtype=float32)\n",
      "sess.run(node3):  [  7.           6.22445011  11.        ]\n"
     ]
    }
   ],
   "source": [
    "node3 = tf.add(node1, node2)\n",
    "print(\"node3: \", node3)\n",
    "print(\"sess.run(node3): \",sess.run(node3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Till now we dealt with constants, now placeholders that can have different values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.5\n",
      "[ 3.  7.]\n"
     ]
    }
   ],
   "source": [
    "a = tf.placeholder(tf.float32)\n",
    "b = tf.placeholder(tf.float32)\n",
    "adder_node = a + b  # + provides a shortcut for tf.add(a, b)\n",
    "print(sess.run(adder_node, {a: 3, b:4.5}))\n",
    "print(sess.run(adder_node, {a: [1,3], b: [2, 4]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might think why we take the model as y = W*x + b and not something else, it is because it can be proven that such neural networks in combination in layers can compute any function.\n",
    "<br>http://neuralnetworksanddeeplearning.com/chap4.html  -- check this link for proof"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>A single Node linear Neuron</b>\n",
    "\n",
    "In this neuron we have inputs as x = {1,2,3,4} and corresponding outputs as y = {0,-1,-2,-3},<br> we want to train our neuron to map this function.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.]\n",
      "[ 0.          0.30000001  0.60000002  0.90000004]\n"
     ]
    }
   ],
   "source": [
    "W = tf.Variable([.3], tf.float32)\n",
    "b = tf.Variable([-.3], tf.float32)\n",
    "x = tf.placeholder(tf.float32)\n",
    "linear_model = W * x + b\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "print(sess.run(linear_model, {x:1}))\n",
    "print(sess.run(linear_model, {x:[1.,2.,3.,4.]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.           1.68999982   6.75999928  15.21000099]\n",
      "23.66\n"
     ]
    }
   ],
   "source": [
    "y = tf.placeholder(tf.float32)\n",
    "squared_deltas = tf.square(linear_model - y)\n",
    "print(sess.run(squared_deltas, {x:[1,2,3,4], y:[0,-1,-2,-3]}))\n",
    "loss = tf.reduce_sum(squared_deltas)\n",
    "print(sess.run(loss, {x:[1,2,3,4], y:[0,-1,-2,-3]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "fixW = tf.assign(W, [-1.])\n",
    "fixb = tf.assign(b, [1.])\n",
    "sess.run([fixW, fixb])\n",
    "print(sess.run(loss, {x:[1,2,3,4], y:[0,-1,-2,-3]}))\n",
    "#manually changing W and b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Using TensorFlow to train model</b>\n",
    "\n",
    "    We try same models with different learning rates and number of iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learn_rate = 0.01\n",
    "num_iter = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter no:0  ,[array([ 0.30000001], dtype=float32), array([-0.30000001], dtype=float32)]\n",
      "iter no:1  ,[array([-0.21999997], dtype=float32), array([-0.456], dtype=float32)]\n",
      "iter no:100  ,[array([-0.84079814], dtype=float32), array([ 0.53192717], dtype=float32)]\n",
      "iter no:101  ,[array([-0.84270465], dtype=float32), array([ 0.53753263], dtype=float32)]\n",
      "iter no:200  ,[array([-0.95227844], dtype=float32), array([ 0.85969269], dtype=float32)]\n",
      "iter no:201  ,[array([-0.95284992], dtype=float32), array([ 0.86137295], dtype=float32)]\n",
      "iter no:300  ,[array([-0.98569524], dtype=float32), array([ 0.95794231], dtype=float32)]\n",
      "iter no:301  ,[array([-0.98586655], dtype=float32), array([ 0.95844597], dtype=float32)]\n",
      "iter no:400  ,[array([-0.99571204], dtype=float32), array([ 0.98739296], dtype=float32)]\n",
      "iter no:401  ,[array([-0.99576342], dtype=float32), array([ 0.98754394], dtype=float32)]\n",
      "iter no:500  ,[array([-0.99871475], dtype=float32), array([ 0.99622124], dtype=float32)]\n",
      "iter no:501  ,[array([-0.99873012], dtype=float32), array([ 0.99626648], dtype=float32)]\n",
      "iter no:600  ,[array([-0.99961478], dtype=float32), array([ 0.99886739], dtype=float32)]\n",
      "iter no:601  ,[array([-0.99961936], dtype=float32), array([ 0.99888098], dtype=float32)]\n",
      "iter no:700  ,[array([-0.99988455], dtype=float32), array([ 0.99966055], dtype=float32)]\n",
      "iter no:701  ,[array([-0.99988592], dtype=float32), array([ 0.9996646], dtype=float32)]\n",
      "iter no:800  ,[array([-0.99996537], dtype=float32), array([ 0.99989825], dtype=float32)]\n",
      "iter no:801  ,[array([-0.99996579], dtype=float32), array([ 0.99989945], dtype=float32)]\n",
      "iter no:900  ,[array([-0.99998957], dtype=float32), array([ 0.99996936], dtype=float32)]\n",
      "iter no:901  ,[array([-0.99998969], dtype=float32), array([ 0.99996972], dtype=float32)]\n",
      "[array([-0.9999969], dtype=float32), array([ 0.99999082], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learn_rate)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "sess.run(init) # reset values to incorrect defaults.\n",
    "for i in range(num_iter):\n",
    "    if(i%100 == 0 or (i-1)%100 == 0):\n",
    "        print(\"iter no:\"+ str(i) +\"  ,\"+ str(sess.run([W, b])))\n",
    "    sess.run(train, {x:[1,2,3,4], y:[0,-1,-2,-3]})\n",
    "\n",
    "print(sess.run([W, b]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [tensorenv]",
   "language": "python",
   "name": "Python [tensorenv]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
